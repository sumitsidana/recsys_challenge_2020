{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\"text_ tokens\"]\n",
    "\n",
    "test = pd.read_csv(\"s3://recsys-challenge-2020/competition_test.tsv\", encoding=\"utf-8\",\n",
    "                    names = all_features, usecols= [0], sep=\"\\x01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text(row):\n",
    "    tweet_tokens = tokenizer.decode(list(map(int, row.split('\\t'))))\n",
    "    return tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text['user_text'] = test['text_ tokens'].apply(lambda x: calculate_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.to_csv('s3://recsys-challenge-2020/test_set_text.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(row, index):\n",
    "    if index % 100000 == 0:\n",
    "        print(index)\n",
    "    row1 = row.replace('[CLS]','')\n",
    "    row2 = row1.replace('[SEP]', '')\n",
    "    result = re.sub(r\"http\\S+\", \"\", row2)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    token_list = tokenizer.tokenize(result)\n",
    "    feature =  ' '.join([w.lower() for w in token_list])\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_test['tweet_text'] = test_text.apply(lambda x: tokenize_text(x.user_text, x.name), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\"language\"]\n",
    "test = pd.read_csv(\"s3://recsys-challenge-2020/competition_test.tsv\", encoding=\"utf-8\",\n",
    "                    names = all_features, usecols= [7], sep=\"\\x01\"\n",
    "                   )\n",
    "print('test language loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_code_name_pairs = pd.read_csv('s3://recsys-challenge-2020/language_code_name_pairs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = pd.merge(test, language_code_name_pairs, how = 'inner',\\\n",
    "left_on = 'language', right_on = 'code')[['name']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
