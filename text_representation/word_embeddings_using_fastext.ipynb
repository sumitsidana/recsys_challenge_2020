{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to import 'smart_open.gcs', disabling that module\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import boto3\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "from boto3.s3.transfer import TransferConfig\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "import gensim\n",
    "from gensim import models\n",
    "from gensim import corpora\n",
    "import lda\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = pd.read_csv('s3://recsys-challenge-2020/train_input.csv')\n",
    "val_input = pd.read_csv('s3://recsys-challenge-2020/val_input.csv')\n",
    "test_input = pd.read_csv('s3://recsys-challenge-2020/test_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>envivo buenas noches comienza una nueva edició...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>esta bebé nació con una marca que la ha hecho ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>elsalvador el tiempo y el olvido juegan en con...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>menciona a la mane _ acasore de tu karime _ ac...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ddn apocalipsis zombi tras visitar otra agenci...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text name\n",
       "0  envivo buenas noches comienza una nueva edició...   pt\n",
       "1  esta bebé nació con una marca que la ha hecho ...   pt\n",
       "2  elsalvador el tiempo y el olvido juegan en con...   pt\n",
       "3  menciona a la mane _ acasore de tu karime _ ac...   pt\n",
       "4  ddn apocalipsis zombi tras visitar otra agenci...   pt"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input.index = train_input.index.astype(str) + '_train'\n",
    "val_input.index = val_input.index.astype(str) + '_val'\n",
    "test_input.index = test_input.index.astype(str) + '_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_input, val_input, test_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0_train</th>\n",
       "      <td>envivo buenas noches comienza una nueva edició...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1_train</th>\n",
       "      <td>esta bebé nació con una marca que la ha hecho ...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2_train</th>\n",
       "      <td>elsalvador el tiempo y el olvido juegan en con...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3_train</th>\n",
       "      <td>menciona a la mane _ acasore de tu karime _ ac...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4_train</th>\n",
       "      <td>ddn apocalipsis zombi tras visitar otra agenci...</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet_text name\n",
       "0_train  envivo buenas noches comienza una nueva edició...   pt\n",
       "1_train  esta bebé nació con una marca que la ha hecho ...   pt\n",
       "2_train  elsalvador el tiempo y el olvido juegan en con...   pt\n",
       "3_train  menciona a la mane _ acasore de tu karime _ ac...   pt\n",
       "4_train  ddn apocalipsis zombi tras visitar otra agenci...   pt"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163202921"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_input = all_data.sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = list(full_input.name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['af',\n",
       " 'ar',\n",
       " 'bg',\n",
       " 'bn',\n",
       " 'ca',\n",
       " 'de',\n",
       " 'el',\n",
       " 'en',\n",
       " 'et',\n",
       " 'fa',\n",
       " 'fi',\n",
       " 'fr',\n",
       " 'gu',\n",
       " 'he',\n",
       " 'hr',\n",
       " 'hu',\n",
       " 'id',\n",
       " 'it',\n",
       " 'ja',\n",
       " 'kn',\n",
       " 'ko',\n",
       " 'lv',\n",
       " 'mk',\n",
       " 'ml',\n",
       " 'mr',\n",
       " 'pa',\n",
       " 'pt',\n",
       " 'ru',\n",
       " 'sw',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tl',\n",
       " 'tr',\n",
       " 'ur',\n",
       " 'vi']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_sentence_embedding(row, ft):\n",
    "    if pd.isna(row):\n",
    "        return np.zeros(20)\n",
    "    return ft.get_sentence_vector(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_output = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting langage: en\n",
      "number of lines to compute: 80296505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    if (language == 'af') or (language == 'ar') or (language == 'bg') or (language == 'bn')\\\n",
    "    or (language == 'ca') or (language == 'de') or (language == 'el'):\n",
    "        continue\n",
    "    print('starting langage: ' + language)\n",
    "    lang_output = pd.DataFrame()\n",
    "    lang_input = full_input.loc[full_input.name == language]\n",
    "    print('number of lines to compute: ' + str(len(lang_input)))\n",
    "    fasttext.util.download_model(language, if_exists='ignore')  # English\n",
    "    ft = fasttext.load_model('cc.'+language+'.300.bin')\n",
    "    fasttext.util.reduce_model(ft, 20)\n",
    "    lang_output['sentence_embedding'] = lang_input.apply(lambda x: get_fasttext_sentence_embedding(x.tweet_text, ft), axis = 1)\n",
    "    all_lang_output = pd.concat([all_lang_output, lang_output])\n",
    "    print('finished language: ' + language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ./cc.*.300.bin*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_output.to_csv('./all_lang_output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try parallelization with English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fasttext_sentence_embedding_try(row, ft):\n",
    "    if pd.isna(row['tweet_text']):\n",
    "        return np.zeros(20)\n",
    "    return ft.get_sentence_vector(row['tweet_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count, Pool\n",
    "\n",
    "cores = cpu_count() #Number of CPU cores on your system\n",
    "partitions = cores #Define as many partitions as you want\n",
    " \n",
    "def parallelize(data, func):\n",
    "    data_split = np.array_split(data, partitions)\n",
    "    pool = Pool(cores)\n",
    "    data = pd.concat(pool.map(func(ft), data_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return data\n",
    "\n",
    "lang_output = pd.DataFrame()\n",
    "lang_output['sentence_embedding'] = parallelize(lang_input[['tweet_text']], get_fasttext_sentence_embedding_try(ft));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('starting langage: ' + 'en')\n",
    "lang_output = pd.DataFrame()\n",
    "#lang_input = full_input.loc[full_input.name == 'en']\n",
    "ddata = dd.from_pandas(lang_input, npartitions = 96)\n",
    "print('number of lines to compute: ' + str(len(lang_input)))\n",
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.'+'en'+'.300.bin')\n",
    "fasttext.util.reduce_model(ft, 20)\n",
    "lang_output['sentence_embedding'] = ddata.map_partitions(lambda lang_input: lang_input.apply((lambda x: get_fasttext_sentence_embedding(x.tweet_text, ft)), axis = 1)).compute(scheduler='processes')\n",
    "# res = ddata.map_partitions(lambda df: df.apply((lambda row: myfunc(*row)), axis=1)).compute(get=get)\n",
    "print('finished en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_output['sentence_embedding'] = ddata.map_partitions(lambda lang_input: lang_input.apply((lambda x: get_fasttext_sentence_embedding(x.tweet_text, ft)), axis = 1)).compute(scheduler='processes')\n",
    "# res = ddata.map_partitions(lambda df: df.apply((lambda row: myfunc(*row)), axis=1)).compute(get=get)\n",
    "print('finished en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_output = pd.concat([all_lang_output, lang_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "fasttext.util.reduce_model(ft, 20)\n",
    "lang_output = pd.DataFrame()\n",
    "lang_input = full_input.loc[full_input.name == 'en']\n",
    "lang_output['sentence_embedding'] = lang_input.apply(lambda x: get_fasttext_sentence_embedding(x.tweet_text), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lang_output = all_lang_output.concat([all_lang_output, lang_output])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
