{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import s3fs\n",
    "import boto3\n",
    "from io import StringIO # python3; python2: BytesIO \n",
    "from boto3.s3.transfer import TransferConfig\n",
    "import torch\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "import re\n",
    "from langdetect import detect\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The goal: Get text corresponding to train set and validation set and Language corresponding to it.\n",
    "\n",
    "# Output should look like: Cleaned text and Language corresponding to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide timesamp and Language into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(row, index):\n",
    "    if index % 100000 == 0:\n",
    "        print(index)\n",
    "    row1 = row.replace('[CLS]','')\n",
    "    row2 = row1.replace('[SEP]', '')\n",
    "    result = re.sub(r\"http\\S+\", \"\", row2)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    token_list = tokenizer.tokenize(result)\n",
    "    feature =  ' '.join([w.lower() for w in token_list])\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_detect(str1, str2):\n",
    "    return str1,detect(str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\"Language\", \"tweet_timestamp\", \"engaging_user_id\", \"reply_timestamp\"]\n",
    "\n",
    "train = pd.read_csv(\"s3://recsys-challenge-2020/training.tsv\", encoding=\"utf-8\",\n",
    "                    names = all_features, usecols= [7, 8, 14, 20], sep=\"\\x01\")\n",
    "train_sorted = train.sort_values(by=['tweet_timestamp']).reset_index()\n",
    "n_head = 90\n",
    "n_tail = 10\n",
    "train_set = train_sorted.head(int(len(train_sorted)*(n_head/100)))\n",
    "val_set = train_sorted.tail(int(len(train_sorted)*(n_tail/100))).reset_index()\n",
    "train_set_text = pd.read_csv('s3://recsys-challenge-2020/train_set_text.csv')\n",
    "val_set_text = pd.read_csv('s3://recsys-challenge-2020/val_set_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lda_input = pd.concat([train_set, train_set_text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lda_input = pd.concat([val_set, val_set_text], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lda_input.to_csv('s3://recsys-challenge-2020/train_lda_input.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lda_input.to_csv('s3://recsys-challenge-2020/val_lda_input.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lda_input = pd.read_csv('s3://recsys-challenge-2020/train_lda_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_train = pd.DataFrame()\n",
    "#cleaned_text_val = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n",
      "12100000\n",
      "12200000\n",
      "12300000\n",
      "12400000\n",
      "12500000\n",
      "12600000\n",
      "12700000\n",
      "12800000\n",
      "12900000\n"
     ]
    }
   ],
   "source": [
    "cleaned_text_train['tweet_text'] = train_lda_input.apply(lambda x: tokenize_text(x.user_text, x.name), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_train.to_csv('s3://recsys-challenge-2020/cleaned_text_train.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>envivo buenas noches comienza una nueva edició...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>celebrate lunar new year with the new tigeress...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>the media tend not to feature abortion survivo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>porto alegre tem novidade na agenda unk 14 de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>karnataka boy who guided ambulance during floo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text\n",
       "0  envivo buenas noches comienza una nueva edició...\n",
       "1  celebrate lunar new year with the new tigeress...\n",
       "2  the media tend not to feature abortion survivo...\n",
       "3  porto alegre tem novidade na agenda unk 14 de ...\n",
       "4  karnataka boy who guided ambulance during floo..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133267714"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_val = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_lda_input = pd.read_csv('s3://recsys-challenge-2020/val_lda_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n",
      "12100000\n",
      "12200000\n",
      "12300000\n",
      "12400000\n",
      "12500000\n",
      "12600000\n",
      "12700000\n",
      "12800000\n",
      "12900000\n",
      "13000000\n",
      "13100000\n",
      "13200000\n",
      "13300000\n",
      "13400000\n",
      "13500000\n",
      "13600000\n",
      "13700000\n",
      "13800000\n",
      "13900000\n",
      "14000000\n",
      "14100000\n",
      "14200000\n",
      "14300000\n",
      "14400000\n",
      "14500000\n",
      "14600000\n",
      "14700000\n",
      "14800000\n"
     ]
    }
   ],
   "source": [
    "cleaned_text_val['tweet_text'] = val_lda_input.apply(lambda x: tokenize_text(x.user_text, x.name), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_train= train_lda_input.groupby('Language').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>sm 사옥빌딩 앞에 있는 전광판차 사진들입니다 전광판차는 사옥 앞에서 오늘 아침 9시부터 오후 4시까지 있을 예정입니다 weareoneexo exo 엑소 t co cs70eh6ikt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>방송 막하지 말라던 최민호는 본인이 막히기 시작하는데 t co wqz58zzz5l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rt reportertelly let s just check it out according to you who is the most deserving contestant among these two asimriaz sidharthsh unk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>abhirupkumardu1 जय म</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rt lovablebh _ 0506 백현이 오늘 심각하게 unk 던지고 가만히 서서 빵싯 웃는 거 unk 뛰어 내려갈 때는 또 얼마나 unk t co j9e1xykief</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                               tweet_text\n",
       "0  sm 사옥빌딩 앞에 있는 전광판차 사진들입니다 전광판차는 사옥 앞에서 오늘 아침 9시부터 오후 4시까지 있을 예정입니다 weareoneexo exo 엑소 t co cs70eh6ikt                                 \n",
       "1  방송 막하지 말라던 최민호는 본인이 막히기 시작하는데 t co wqz58zzz5l                                                                                         \n",
       "2  rt reportertelly let s just check it out according to you who is the most deserving contestant among these two asimriaz sidharthsh unk\n",
       "3  abhirupkumardu1 जय म                                                                                                                  \n",
       "4  rt lovablebh _ 0506 백현이 오늘 심각하게 unk 던지고 가만히 서서 빵싯 웃는 거 unk 뛰어 내려갈 때는 또 얼마나 unk t co j9e1xykief                                        "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_val.to_csv('s3://recsys-challenge-2020/cleaned_text_val.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work with test data now to get the clean text of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\"text_ tokens\"]\n",
    "\n",
    "test = pd.read_csv(\"s3://recsys-challenge-2020/val.tsv\", encoding=\"utf-8\",\n",
    "                    names = all_features, usecols= [0], sep=\"\\x01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text(row):\n",
    "    tweet_tokens = tokenizer.decode(list(map(int, row.split('\\t'))))\n",
    "    return tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text['user_text'] = test['text_ tokens'].apply(lambda x: calculate_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text.to_csv('s3://recsys-challenge-2020/test_set_text.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n",
      "1200000\n",
      "1300000\n",
      "1400000\n",
      "1500000\n",
      "1600000\n",
      "1700000\n",
      "1800000\n",
      "1900000\n",
      "2000000\n",
      "2100000\n",
      "2200000\n",
      "2300000\n",
      "2400000\n",
      "2500000\n",
      "2600000\n",
      "2700000\n",
      "2800000\n",
      "2900000\n",
      "3000000\n",
      "3100000\n",
      "3200000\n",
      "3300000\n",
      "3400000\n",
      "3500000\n",
      "3600000\n",
      "3700000\n",
      "3800000\n",
      "3900000\n",
      "4000000\n",
      "4100000\n",
      "4200000\n",
      "4300000\n",
      "4400000\n",
      "4500000\n",
      "4600000\n",
      "4700000\n",
      "4800000\n",
      "4900000\n",
      "5000000\n",
      "5100000\n",
      "5200000\n",
      "5300000\n",
      "5400000\n",
      "5500000\n",
      "5600000\n",
      "5700000\n",
      "5800000\n",
      "5900000\n",
      "6000000\n",
      "6100000\n",
      "6200000\n",
      "6300000\n",
      "6400000\n",
      "6500000\n",
      "6600000\n",
      "6700000\n",
      "6800000\n",
      "6900000\n",
      "7000000\n",
      "7100000\n",
      "7200000\n",
      "7300000\n",
      "7400000\n",
      "7500000\n",
      "7600000\n",
      "7700000\n",
      "7800000\n",
      "7900000\n",
      "8000000\n",
      "8100000\n",
      "8200000\n",
      "8300000\n",
      "8400000\n",
      "8500000\n",
      "8600000\n",
      "8700000\n",
      "8800000\n",
      "8900000\n",
      "9000000\n",
      "9100000\n",
      "9200000\n",
      "9300000\n",
      "9400000\n",
      "9500000\n",
      "9600000\n",
      "9700000\n",
      "9800000\n",
      "9900000\n",
      "10000000\n",
      "10100000\n",
      "10200000\n",
      "10300000\n",
      "10400000\n",
      "10500000\n",
      "10600000\n",
      "10700000\n",
      "10800000\n",
      "10900000\n",
      "11000000\n",
      "11100000\n",
      "11200000\n",
      "11300000\n",
      "11400000\n",
      "11500000\n",
      "11600000\n",
      "11700000\n",
      "11800000\n",
      "11900000\n",
      "12000000\n",
      "12100000\n",
      "12200000\n",
      "12300000\n",
      "12400000\n",
      "12500000\n",
      "12600000\n",
      "12700000\n",
      "12800000\n",
      "12900000\n",
      "13000000\n",
      "13100000\n",
      "13200000\n",
      "13300000\n",
      "13400000\n",
      "13500000\n",
      "13600000\n",
      "13700000\n",
      "13800000\n",
      "13900000\n",
      "14000000\n",
      "14100000\n",
      "14200000\n",
      "14300000\n",
      "14400000\n",
      "14500000\n",
      "14600000\n",
      "14700000\n",
      "14800000\n",
      "14900000\n",
      "15000000\n",
      "15100000\n"
     ]
    }
   ],
   "source": [
    "cleaned_text_test['tweet_text'] = test_text.apply(lambda x: tokenize_text(x.user_text, x.name), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text_test.to_csv('s3://recsys-challenge-2020/cleaned_text_test.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>funky techno witch t co ydfhit7ncn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>空 港 で 財 布 置 き 忘 れたら 偶 然 隣 座 ってた 方 がフォロワーさんで 渡 しにきてくれた 本 当 にありがとう 堂 々と 横 で 仕 事 しててよかった t co pvwxertu0p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rt legadodekonoha eis o verdadeiro significado de sonho de consumo para um fã de naruto t co w5boqyhfpo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>para uma criança pequenina que verá um pouco mais do mundo a partir de hoje e para outra não tão pequenina que já aprendeu um pouquinho a ver o mundo com os próprios olhos t co x5k7a1dc65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>why lesbian couples are more likely to divorce than gay ones t co ccsxngoeyl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                    tweet_text\n",
       "0  funky techno witch t co ydfhit7ncn                                                                                                                                                         \n",
       "1  空 港 で 財 布 置 き 忘 れたら 偶 然 隣 座 ってた 方 がフォロワーさんで 渡 しにきてくれた 本 当 にありがとう 堂 々と 横 で 仕 事 しててよかった t co pvwxertu0p                                                                                      \n",
       "2  rt legadodekonoha eis o verdadeiro significado de sonho de consumo para um fã de naruto t co w5boqyhfpo                                                                                    \n",
       "3  para uma criança pequenina que verá um pouco mais do mundo a partir de hoje e para outra não tão pequenina que já aprendeu um pouquinho a ver o mundo com os próprios olhos t co x5k7a1dc65\n",
       "4  why lesbian couples are more likely to divorce than gay ones t co ccsxngoeyl                                                                                                               "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the name of the languages for codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_val = val_lda_input.groupby('Language').first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_code_name_pairs = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_code_name_pairs['code'], language_code_name_pairs['name'] = zip(*group_val.apply(lambda x : language_detect(x.Language, x.user_text), axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>022EC308651FACB02794A8147AEE1B78</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0331BF70E606D62D92C96CE9AD71A7CF</td>\n",
       "      <td>fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>06BEAB41D66CCFF329D1ED8BA120A6C2</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>06D61DCBBE938971E1EA0C38BD9B5446</td>\n",
       "      <td>pt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>125C57F4FA6D4E110983FB11B52EFD4E</td>\n",
       "      <td>ko</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               code name\n",
       "0  022EC308651FACB02794A8147AEE1B78  en \n",
       "1  0331BF70E606D62D92C96CE9AD71A7CF  fi \n",
       "2  06BEAB41D66CCFF329D1ED8BA120A6C2  he \n",
       "3  06D61DCBBE938971E1EA0C38BD9B5446  pt \n",
       "4  125C57F4FA6D4E110983FB11B52EFD4E  ko "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "language_code_name_pairs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_code_name_pairs.to_csv('s3://recsys-challenge-2020/language_code_name_pairs.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get input of format: clean text, language name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>envivo buenas noches comienza una nueva edición de 24horascentral junto a iván núñez unk sigue la señal en vivo 24play unk t co mi3yduas2f t co y6qu6gwdcl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>celebrate lunar new year with the new tigeress and swift outfits in the item shop now t co ojiwhkcp5o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>the media tend not to feature abortion survivors like claire culwell a woman whose story has in recent years captivated the pro life world t co cowpnipsgk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>porto alegre tem novidade na agenda unk 14 de março eu toco no teatro do sesc _ rs e já tô muito ansiosa pra rever todo mundo ingressos aqui t co ihrnvhrb1p t co hyjf3917d1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>karnataka boy who guided ambulance during floods to be awarded on republicday t co qotzvndlme t co hrgzbclncv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                     tweet_text\n",
       "0  envivo buenas noches comienza una nueva edición de 24horascentral junto a iván núñez unk sigue la señal en vivo 24play unk t co mi3yduas2f t co y6qu6gwdcl                  \n",
       "1  celebrate lunar new year with the new tigeress and swift outfits in the item shop now t co ojiwhkcp5o                                                                       \n",
       "2  the media tend not to feature abortion survivors like claire culwell a woman whose story has in recent years captivated the pro life world t co cowpnipsgk                  \n",
       "3  porto alegre tem novidade na agenda unk 14 de março eu toco no teatro do sesc _ rs e já tô muito ansiosa pra rever todo mundo ingressos aqui t co ihrnvhrb1p t co hyjf3917d1\n",
       "4  karnataka boy who guided ambulance during floods to be awarded on republicday t co qotzvndlme t co hrgzbclncv                                                               "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Language</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>engaging_user_id</th>\n",
       "      <th>reply_timestamp</th>\n",
       "      <th>user_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>19856362</td>\n",
       "      <td>06D61DCBBE938971E1EA0C38BD9B5446</td>\n",
       "      <td>1580947200</td>\n",
       "      <td>12A1AF0088C5B4FCBFA024D4A1971323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[CLS] # ENVIVO | ¡ Buenas noches! Comienza una nueva edición de # 24HorasCentral junto a Iván Núñez... [UNK] Sigue la señal en vivo # 24Play [UNK] https : / / t. co / mi3yDUaS2F https : / / t. co / Y6qU6gwdCL [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>70014084</td>\n",
       "      <td>D3164C7FBCF2565DDF915B1B3AEFB1DC</td>\n",
       "      <td>1580947200</td>\n",
       "      <td>C836F432B0FC7847C2C753949C51B961</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[CLS] Celebrate Lunar New Year with the new Tigeress and Swift Outfits in the Item Shop now! https : / / t. co / oJIWHkCp5o [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>45640141</td>\n",
       "      <td>D3164C7FBCF2565DDF915B1B3AEFB1DC</td>\n",
       "      <td>1580947200</td>\n",
       "      <td>77309DE08AB631D8224254D33648F287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[CLS] The media tend not to feature abortion survivors like Claire Culwell, a woman whose story has in recent years captivated the pro - life world.. https : / / t. co / COWpNipsgk [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>103063682</td>\n",
       "      <td>ECED8A16BE2A5E8871FD55F4842F16B1</td>\n",
       "      <td>1580947200</td>\n",
       "      <td>91363F238C79DAEE42E2A2C97A5F8E7C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[CLS] porto alegre, tem novidade na agenda [UNK] 14 de março eu toco no teatro do @ sesc _ rs e já tô muito ansiosa pra rever todo mundo. ingressos aqui : https : / / t. co / ihrnvHrB1P https : / / t. co / HyJf3917d1 [SEP]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>54351326</td>\n",
       "      <td>D3164C7FBCF2565DDF915B1B3AEFB1DC</td>\n",
       "      <td>1580947200</td>\n",
       "      <td>EFA4C5B62E097EB203F8AFDC470AEB27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[CLS] Karnataka boy, who guided ambulance during floods, to be awarded on # RepublicDay.. https : / / t. co / qOtzvndLmE https : / / t. co / HRGZbClnCv [SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                          Language  tweet_timestamp  \\\n",
       "0  19856362   06D61DCBBE938971E1EA0C38BD9B5446  1580947200        \n",
       "1  70014084   D3164C7FBCF2565DDF915B1B3AEFB1DC  1580947200        \n",
       "2  45640141   D3164C7FBCF2565DDF915B1B3AEFB1DC  1580947200        \n",
       "3  103063682  ECED8A16BE2A5E8871FD55F4842F16B1  1580947200        \n",
       "4  54351326   D3164C7FBCF2565DDF915B1B3AEFB1DC  1580947200        \n",
       "\n",
       "                   engaging_user_id  reply_timestamp  \\\n",
       "0  12A1AF0088C5B4FCBFA024D4A1971323 NaN                \n",
       "1  C836F432B0FC7847C2C753949C51B961 NaN                \n",
       "2  77309DE08AB631D8224254D33648F287 NaN                \n",
       "3  91363F238C79DAEE42E2A2C97A5F8E7C NaN                \n",
       "4  EFA4C5B62E097EB203F8AFDC470AEB27 NaN                \n",
       "\n",
       "                                                                                                                                                                                                                        user_text  \n",
       "0  [CLS] # ENVIVO | ¡ Buenas noches! Comienza una nueva edición de # 24HorasCentral junto a Iván Núñez... [UNK] Sigue la señal en vivo # 24Play [UNK] https : / / t. co / mi3yDUaS2F https : / / t. co / Y6qU6gwdCL [SEP]          \n",
       "1  [CLS] Celebrate Lunar New Year with the new Tigeress and Swift Outfits in the Item Shop now! https : / / t. co / oJIWHkCp5o [SEP]                                                                                               \n",
       "2  [CLS] The media tend not to feature abortion survivors like Claire Culwell, a woman whose story has in recent years captivated the pro - life world.. https : / / t. co / COWpNipsgk [SEP]                                      \n",
       "3  [CLS] porto alegre, tem novidade na agenda [UNK] 14 de março eu toco no teatro do @ sesc _ rs e já tô muito ansiosa pra rever todo mundo. ingressos aqui : https : / / t. co / ihrnvHrB1P https : / / t. co / HyJf3917d1 [SEP]  \n",
       "4  [CLS] Karnataka boy, who guided ambulance during floods, to be awarded on # RepublicDay.. https : / / t. co / qOtzvndLmE https : / / t. co / HRGZbClnCv [SEP]                                                                   "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lda_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clean_input = pd.concat([train_lda_input[['Language']], cleaned_text_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_clean_input = pd.concat([val_lda_input[['Language']], cleaned_text_val], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [\"Language\"]\n",
    "\n",
    "test_language = pd.read_csv(\"s3://recsys-challenge-2020/val.tsv\", encoding=\"utf-8\",\n",
    "                    names = all_features, usecols= [7], sep=\"\\x01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_clean_input = pd.concat([test_language[['Language']], cleaned_text_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = pd.merge(train_clean_input, language_code_name_pairs, how = 'inner',\\\n",
    "left_on = 'Language', right_on = 'code')[['tweet_text', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_input = pd.merge(val_clean_input, language_code_name_pairs, how = 'inner',\\\n",
    "left_on = 'Language', right_on = 'code')[['tweet_text', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = pd.merge(test_clean_input, language_code_name_pairs, how = 'inner',\\\n",
    "left_on = 'Language', right_on = 'code')[['tweet_text', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input.to_csv('s3://recsys-challenge-2020/train_input.csv', index = False)\n",
    "val_input.to_csv('s3://recsys-challenge-2020/val_input.csv', index = False)\n",
    "test_input.to_csv('s3://recsys-challenge-2020/test_input.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
