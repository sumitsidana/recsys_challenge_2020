{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "from datetime import datetime\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### language, tweet_timestamp, enaged_with_user_id, engaged_with_user_follower_count, engaged_with_user_following_count, enaging_user_id, \n",
    "\n",
    "### enaging_user_follower_count, enaging_user_following_count, retweet_with_comment_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ep_to_day(ep):\n",
    "    return datetime.datetime.fromtimestamp(ep).weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['language', 'tweet_timestamp', 'enaged_with_user_id', 'engaged_with_user_follower_count',\\\n",
    "         'engaged_with_user_following_count', 'enaging_user_id', 'enaging_user_follower_count',\\\n",
    "         'enaging_user_following_count', 'retweet_with_comment_timestamp']\n",
    "\n",
    "training = pd.read_csv('s3://recsys-challenge-2020/training.tsv', usecols = [7, 8, 9, 10, 11, 14, 15, 16, 22],\n",
    "                       names = names, encoding=\"utf-8\", sep=\"\\x01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/training.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training['day_of_tweet'] = training.swifter.allow_dask_on_strings(enable=True).apply(lambda x: ep_to_day(x['tweet_timestamp'])\\\n",
    "                                        , axis  = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/training_day.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "x = training[['engaged_with_user_follower_count', \"engaged_with_user_following_count\",\\\n",
    "                \"enaging_user_follower_count\", \"enaging_user_following_count\"]].values #returns a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "training_scaled = pd.concat([training, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scaled['retweet_with_comment_bool'] = training_scaled.retweet_with_comment_timestamp.fillna(0)\n",
    "training_scaled.loc[training_scaled.retweet_with_comment_bool != 0.0, 'retweet_with_comment_bool'] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.retweet_with_comment_bool.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scaled.rename(columns = {0:'engaged_with_user_follower_count_scaled'\\\n",
    "                     ,1:'engaged_with_user_following_count_scaled'\\\n",
    "                     ,2:'enaging_user_follower_count_scaled',\\\n",
    "                     3:'enaging_user_following_count_scaled'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scaled[['language', 'enaged_with_user_id', 'enaging_user_id', 'day_of_tweet',\\\n",
    "                'engaged_with_user_follower_count_scaled', 'engaged_with_user_following_count_scaled',\\\n",
    "               'enaging_user_follower_count_scaled', 'enaging_user_following_count_scaled',\\\n",
    "                'retweet_with_comment_bool']].to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/training_scaled.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = training_scaled[['language', 'enaged_with_user_id', 'enaging_user_id', 'day_of_tweet',\\\n",
    "                'engaged_with_user_follower_count_scaled', 'engaged_with_user_following_count_scaled',\\\n",
    "               'enaging_user_follower_count_scaled', 'enaging_user_following_count_scaled',\\\n",
    "                'retweet_with_comment_bool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data.set_index(keys=['day_of_tweet'], drop=False,inplace=True)\n",
    "names = training_data['day_of_tweet'].unique().tolist()\n",
    "train_scratch = pd.DataFrame()\n",
    "val_scratch = pd.DataFrame()\n",
    "for day in names:\n",
    "    print(day)\n",
    "    train_day = training_data.loc[training_data.day_of_tweet==day]\n",
    "    n_head = 90\n",
    "    n_tail = 10\n",
    "    train_set_scratch = train_day.head(int(len(train_day)*(n_head/100)))\n",
    "    val_set_scratch = train_day.tail(int(len(train_day)*(n_tail/100)))\n",
    "    train_scratch = pd.concat([train_scratch, train_set_scratch])\n",
    "    val_scratch = pd.concat([val_scratch, val_set_scratch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scratch.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scratch.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scratch.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scratch.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scratch.to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/train_scratch.csv', index = False)\n",
    "val_scratch.to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/val_scratch.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scratch = pd.read_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/train_scratch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scratch = pd.read_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/val_scratch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_scratch,val_scratch],keys=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['day_of_tweet'] = data['day_of_tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LibffmConverter:\n",
    "    \"\"\"Converts an input dataframe to another dataframe in libffm format. A text file of the converted\n",
    "    Dataframe is optionally generated.\n",
    "    .. note::\n",
    "        The input dataframe is expected to represent the feature data in the following schema:\n",
    "        .. code-block:: python\n",
    "            |field-1|field-2|...|field-n|rating|\n",
    "            |feature-1-1|feature-2-1|...|feature-n-1|1|\n",
    "            |feature-1-2|feature-2-2|...|feature-n-2|0|\n",
    "            ...\n",
    "            |feature-1-i|feature-2-j|...|feature-n-k|0|\n",
    "        Where\n",
    "        1. each `field-*` is the column name of the dataframe (column of label/rating is excluded), and\n",
    "        2. `feature-*-*` can be either a string or a numerical value, representing the categorical variable or\n",
    "        actual numerical variable of the feature value in the field, respectively.\n",
    "        3. If there are ordinal variables represented in int types, users should make sure these columns\n",
    "        are properly converted to string type.\n",
    "        The above data will be converted to the libffm format by following the convention as explained in\n",
    "        `this paper <https://www.csie.ntu.edu.tw/~r01922136/slides/ffm.pdf>`_.\n",
    "        i.e. `<field_index>:<field_feature_index>:1` or `<field_index>:<field_index>:<field_feature_value>`, depending on\n",
    "        the data type of the features in the original dataframe.\n",
    "    Args:\n",
    "        filepath (str): path to save the converted data.\n",
    "    Attributes:\n",
    "        field_count (int): count of field in the libffm format data\n",
    "        feature_count (int): count of feature in the libffm format data\n",
    "        filepath (str or None): file path where the output is stored - it can be None or a string\n",
    "    Examples:\n",
    "        >>> import pandas as pd\n",
    "        >>> df_feature = pd.DataFrame({\n",
    "                'rating': [1, 0, 0, 1, 1],\n",
    "                'field1': ['xxx1', 'xxx2', 'xxx4', 'xxx4', 'xxx4'],\n",
    "                'field2': [3, 4, 5, 6, 7],\n",
    "                'field3': [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                'field4': ['1', '2', '3', '4', '5']\n",
    "            })\n",
    "        >>> converter = LibffmConveter().fit(df_feature, col_rating='rating')\n",
    "        >>> df_out = converter.transform(df_feature)\n",
    "        >>> df_out\n",
    "            rating field1 field2   field3 field4\n",
    "        0       1  1:1:1  2:4:3  3:5:1.0  4:4:1\n",
    "        1       0  1:2:1  2:4:4  3:5:2.0  4:5:1\n",
    "        2       0  1:3:1  2:4:5  3:5:3.0  4:6:1\n",
    "        3       1  1:3:1  2:4:6  3:5:4.0  4:7:1\n",
    "        4       1  1:3:1  2:4:7  3:5:5.0  4:8:1\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, filepath=None):\n",
    "        self.filepath = filepath\n",
    "        self.col_rating = None\n",
    "        self.field_names = None\n",
    "        self.field_count = None\n",
    "        self.feature_count = None\n",
    "\n",
    "    def fit(self, df, col_rating=3):\n",
    "        \"\"\"Fit the dataframe for libffm format.\n",
    "        This method does nothing but check the validity of the input columns\n",
    "        Args:\n",
    "            df (pd.DataFrame): input Pandas dataframe.\n",
    "            col_rating (str): rating of the data.\n",
    "        Return:\n",
    "            obj: the instance of the converter\n",
    "        \"\"\"\n",
    "\n",
    "        # Check column types.\n",
    "        types = df.dtypes\n",
    "        if not all(\n",
    "            [\n",
    "                x == object or np.issubdtype(x, np.integer) or x == np.float\n",
    "                for x in types\n",
    "            ]\n",
    "        ):\n",
    "            raise TypeError(\"Input columns should be only object and/or numeric types.\")\n",
    "\n",
    "        if col_rating not in df.columns:\n",
    "            raise TypeError(\n",
    "                \"Column of {} is not in input dataframe columns\".format(col_rating)\n",
    "            )\n",
    "\n",
    "        self.col_rating = col_rating\n",
    "        self.field_names = list(df.drop(col_rating, axis=1).columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        \"\"\"Tranform an input dataset with the same schema (column names and dtypes) to libffm format \n",
    "        by using the fitted converter.\n",
    "        Args: \n",
    "            df (pd.DataFrame): input Pandas dataframe.\n",
    "        Return:\n",
    "            pd.DataFrame: output libffm format dataframe.\n",
    "        \"\"\"\n",
    "        if self.col_rating not in df.columns:\n",
    "            raise ValueError(\n",
    "                \"Input dataset does not contain the label column {} in the fitting dataset\".format(\n",
    "                    self.col_rating\n",
    "                )\n",
    "            )\n",
    "\n",
    "        if not all([x in df.columns for x in self.field_names]):\n",
    "            raise ValueError(\n",
    "                \"Not all columns in the input dataset appear in the fitting dataset\"\n",
    "            )\n",
    "\n",
    "        # Encode field-feature.\n",
    "        idx = 1\n",
    "        self.field_feature_dict = {}\n",
    "        for field in self.field_names:\n",
    "            for feature in df[field].values:\n",
    "                # Check whether (field, feature) tuple exists in the dict or not.\n",
    "                # If not, put them into the key-values of the dict and count the index.\n",
    "                if (field, feature) not in self.field_feature_dict:\n",
    "                    self.field_feature_dict[(field, feature)] = idx\n",
    "                    if df[field].dtype == object:\n",
    "                        idx += 1\n",
    "            if df[field].dtype != object:\n",
    "                idx += 1\n",
    "\n",
    "        self.field_count = len(self.field_names)\n",
    "        self.feature_count = idx - 1\n",
    "\n",
    "        def _convert(field, feature, field_index, field_feature_index_dict):\n",
    "            field_feature_index = field_feature_index_dict[(field, feature)]\n",
    "            if isinstance(feature, str):\n",
    "                feature = 1\n",
    "            return \"{}:{}:{}\".format(field_index, field_feature_index, feature)\n",
    "\n",
    "        for col_index, col in enumerate(self.field_names):\n",
    "            df[col] = df[col].apply(\n",
    "                lambda x: _convert(col, x, col_index + 1, self.field_feature_dict)\n",
    "            )\n",
    "\n",
    "        # Move rating column to the first.\n",
    "        column_names = self.field_names[:]\n",
    "        column_names.insert(0, self.col_rating)\n",
    "        df = df[column_names]\n",
    "\n",
    "        if self.filepath is not None:\n",
    "            np.savetxt(self.filepath, df.values, delimiter=\" \", fmt=\"%s\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, df, col_rating=4):\n",
    "        \"\"\"Do fit and transform in a row\n",
    "        Args:\n",
    "            df (pd.DataFrame): input Pandas dataframe.\n",
    "            col_rating (str): rating of the data.\n",
    "        Return:\n",
    "            pd.DataFrame: output libffm format dataframe.\n",
    "        \"\"\"\n",
    "        return self.fit(df, col_rating=col_rating).transform(df)\n",
    "\n",
    "    def get_params(self):\n",
    "        \"\"\"Get parameters (attributes) of the libffm converter\n",
    "        Return:\n",
    "            dict: parameters field count, feature count, and file path.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"field count\": self.field_count,\n",
    "            \"feature count\": self.feature_count,\n",
    "            \"file path\": self.filepath,\n",
    "        }\n",
    "\n",
    "\n",
    "    def negative_feedback_sampler(\n",
    "        df,\n",
    "        col_user=0,\n",
    "        col_item=1,\n",
    "        col_label=1,\n",
    "        ratio_neg_per_user=1,\n",
    "        seed=42,\n",
    "    ):\n",
    "        \"\"\"Utility function to sample negative feedback from user-item interaction dataset.\n",
    "        This negative sampling function will take the user-item interaction data to create \n",
    "        binarized feedback, i.e., 1 and 0 indicate positive and negative feedback, \n",
    "        respectively. \n",
    "        Negative sampling is used in the literature frequently to generate negative samples \n",
    "        from a user-item interaction data.\n",
    "        See for example the `neural collaborative filtering paper <https://www.comp.nus.edu.sg/~xiangnan/papers/ncf.pdf>`_.\n",
    "\n",
    "        Args:\n",
    "            df (pandas.DataFrame): input data that contains user-item tuples.\n",
    "            col_user (str): user id column name.\n",
    "            col_item (str): item id column name.\n",
    "            col_label (str): label column name. It is used for the generated columns where labels\n",
    "            of positive and negative feedback, i.e., 1 and 0, respectively, in the output dataframe.\n",
    "            ratio_neg_per_user (int): ratio of negative feedback w.r.t to the number of positive feedback for each user. \n",
    "            If the samples exceed the number of total possible negative feedback samples, it will be reduced to the number\n",
    "            of all the possible samples.\n",
    "            seed (int): seed for the random state of the sampling function.\n",
    "        Returns:\n",
    "            pandas.DataFrame: data with negative feedback \n",
    "        Examples:\n",
    "            >>> import pandas as pd\n",
    "            >>> df = pd.DataFrame({\n",
    "                'userID': [1, 2, 3],\n",
    "                'itemID': [1, 2, 3],\n",
    "                'rating': [5, 5, 5]\n",
    "            })\n",
    "            >>> df_neg_sampled = negative_feedback_sampler(\n",
    "                df, col_user='userID', col_item='itemID', ratio_neg_per_user=1\n",
    "            )\n",
    "            >>> df_neg_sampled\n",
    "            userID  itemID  feedback\n",
    "            1   1   1\n",
    "            1   2   0\n",
    "            2   2   1\n",
    "            2   1   0\n",
    "            3   3   1\n",
    "            3   1   0\n",
    "        \"\"\"\n",
    "        # Get all of the users and items.\n",
    "        users = df[col_user].unique()\n",
    "        items = df[col_item].unique()\n",
    "\n",
    "        # Create a dataframe for all user-item pairs\n",
    "        df_neg = user_item_pairs(\n",
    "            pd.DataFrame(users, columns=[col_user]),\n",
    "            pd.DataFrame(items, columns=[col_item]),\n",
    "            user_item_filter_df=df,\n",
    "        )\n",
    "        df_neg[col_label] = 0\n",
    "\n",
    "        df_pos = df.copy()\n",
    "        df_pos[col_label] = 1\n",
    "\n",
    "        df_all = pd.concat([df_pos, df_neg], ignore_index=True, sort=True)\n",
    "        df_all = df_all[[col_user, col_item, col_label]]\n",
    "\n",
    "        # Sample negative feedback from the combined dataframe.\n",
    "        df_sample = (\n",
    "            df_all.groupby(col_user)\n",
    "            .apply(\n",
    "                lambda x: pd.concat(\n",
    "                    [\n",
    "                        x[x[col_label] == 1],\n",
    "                        x[x[col_label] == 0].sample(\n",
    "                            min(\n",
    "                                max(\n",
    "                                    round(len(x[x[col_label] == 1]) * ratio_neg_per_user), 1\n",
    "                                ),\n",
    "                                len(x[x[col_label] == 0]),\n",
    "                            ),\n",
    "                            random_state=seed,\n",
    "                            replace=False,\n",
    "                        )\n",
    "                        if len(x[x[col_label] == 0] > 0)\n",
    "                        else pd.DataFrame({}, columns=[col_user, col_item, col_label]),\n",
    "                    ],\n",
    "                    ignore_index=True,\n",
    "                    sort=True,\n",
    "                )\n",
    "            )\n",
    "            .reset_index(drop=True)\n",
    "            .sort_values(col_user)\n",
    "        )\n",
    "\n",
    "        return df_sample\n",
    "\n",
    "\n",
    "    def has_columns(df, columns):\n",
    "        \"\"\"Check if DataFrame has necessary columns\n",
    "        Args:\n",
    "            df (pd.DataFrame): DataFrame\n",
    "            columns (list(str): columns to check for\n",
    "        Returns:\n",
    "            bool: True if DataFrame has specified columns\n",
    "        \"\"\"\n",
    "\n",
    "        result = True\n",
    "        for column in columns:\n",
    "            if column not in df.columns:\n",
    "                logger.error(\"Missing column: {} in DataFrame\".format(column))\n",
    "                result = False\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def has_same_base_dtype(df_1, df_2, columns=None):\n",
    "        \"\"\"Check if specified columns have the same base dtypes across both DataFrames\n",
    "        Args:\n",
    "            df_1 (pd.DataFrame): first DataFrame\n",
    "            df_2 (pd.DataFrame): second DataFrame\n",
    "            columns (list(str)): columns to check, None checks all columns\n",
    "        Returns:\n",
    "            bool: True if DataFrames columns have the same base dtypes\n",
    "        \"\"\"\n",
    "\n",
    "        if columns is None:\n",
    "            if any(set(df_1.columns).symmetric_difference(set(df_2.columns))):\n",
    "                logger.error(\n",
    "                    \"Cannot test all columns because they are not all shared across DataFrames\"\n",
    "                )\n",
    "                return False\n",
    "            columns = df_1.columns\n",
    "\n",
    "        if not (\n",
    "            has_columns(df=df_1, columns=columns) and has_columns(df=df_2, columns=columns)\n",
    "        ):\n",
    "            return False\n",
    "\n",
    "        result = True\n",
    "        for column in columns:\n",
    "            if df_1[column].dtype.type.__base__ != df_2[column].dtype.type.__base__:\n",
    "                logger.error(\"Columns {} do not have the same base datatype\".format(column))\n",
    "                result = False\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = LibffmConverter().fit(data, col_rating='retweet_with_comment_bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del [[train_scratch, val_scratch]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scratch = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_scratch = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = converter.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ffm, test_ffm = df_out.xs(0),df_out.xs(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ffm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ffm.to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/train_set.ffm',\\\n",
    "                 index = False, header = False, sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ffm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ffm.to_csv('/home/ubuntu/recsys_challenge_2020/classification_type_models/f3/val_set.ffm',\\\n",
    "                index = False, header = False, sep = ' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Indexes\n",
    "\"text_ tokens\" = 0\n",
    "\"hashtags\" = 1\n",
    "\"tweet_id\" = 2\n",
    "\"present_media\" = 3\n",
    "\"present_links\" = 4\n",
    "\"present_domains\" = 5\n",
    "\"tweet_type\" = 6\n",
    "\"language\" = 7\n",
    "\"tweet_timestamp\" = 8\n",
    "\"enaged_with_user_id\" = 9\n",
    "\"engaged_with_user_follower_count\" = 10\n",
    "\"engaged_with_user_following_count\" = 11\n",
    "\"engaged_with_user_is_verified\" = 12\n",
    "\"engaged_with_user_account_creation\" = 13\n",
    "\"enaging_user_id\" = 14\n",
    "\"enaging_user_follower_count\" = 15\n",
    "\"enaging_user_following_count\" = 16\n",
    "\"enaging_user_is_verified\" = 17\n",
    "\"enaging_user_account_creation\" = 18\n",
    "\"engagee_follows_engager\" = 19\n",
    "\"reply_timestamp\" = 20\n",
    "\"retweet_timestamp\" = 21\n",
    "\"retweet_with_comment_timestamp\" = 22\n",
    "\"like_timestamp\" = 23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
